{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Generic Particle Data\n",
    "\n",
    "This example creates a fake in-memory particle dataset and then loads it as a yt dataset using the `load_particles` function.\n",
    "\n",
    "Our \"fake\" dataset will be numpy arrays filled with normally distributed randoml particle positions and uniform particle masses.  Since real data is often scaled, I arbitrarily multiply by 1e6 to show how to deal with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "n_particles = 5_000_000\n",
    "\n",
    "ppx, ppy, ppz = 1e6 * rng.normal(size=(3, n_particles))\n",
    "\n",
    "ppm = np.ones(n_particles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_particles` function accepts a dictionary populated with particle data fields loaded in memory as numpy arrays or python lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    (\"io\", \"particle_position_x\"): ppx,\n",
    "    (\"io\", \"particle_position_y\"): ppy,\n",
    "    (\"io\", \"particle_position_z\"): ppz,\n",
    "    (\"io\", \"particle_mass\"): ppm,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To hook up with yt's internal field system, the dictionary keys must be 'particle_position_x', 'particle_position_y', 'particle_position_z', and 'particle_mass', as well as any other particle field provided by one of the particle frontends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load_particles` function transforms the `data` dictionary into an in-memory yt `Dataset` object, providing an interface for further analysis with yt. The example below illustrates how to load the data dictionary we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import yt\n",
    "from yt.units import Msun, parsec\n",
    "\n",
    "bbox = 1.1 * np.array(\n",
    "    [[min(ppx), max(ppx)], [min(ppy), max(ppy)], [min(ppz), max(ppz)]]\n",
    ")\n",
    "\n",
    "ds = yt.load_particles(data, length_unit=1.0 * parsec, mass_unit=1e8 * Msun, bbox=bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `length_unit` and `mass_unit` are the conversion from the units used in the `data` dictionary to CGS.  I've arbitrarily chosen one parsec and 10^8 Msun for this example. \n",
    "\n",
    "The `n_ref` parameter controls how many particle it takes to accumulate in an oct-tree cell to trigger refinement.  Larger `n_ref` will decrease poisson noise at the cost of resolution in the octree.  \n",
    "\n",
    "Finally, the `bbox` parameter is a bounding box in the units of the dataset that contains all of the particles.  This is used to set the size of the base octree block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new dataset acts like any other yt `Dataset` object, and can be used to create data objects and query for yt fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ad = ds.all_data()\n",
    "print(ad.mean((\"io\", \"particle_position_x\")))\n",
    "print(ad.sum((\"io\", \"particle_mass\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can project the particle mass field like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prj = yt.ParticleProjectionPlot(ds, \"z\", (\"io\", \"particle_mass\"))\n",
    "prj.set_width((8, \"Mpc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, one can specify multiple particle types in the `data` directory by setting the field names to be field tuples (the default field type for particles is `\"io\"`) if one is not specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gas_particles = 1_000_000\n",
    "n_star_particles = 1_000_000\n",
    "n_dm_particles = 2_000_000\n",
    "\n",
    "ppxg, ppyg, ppzg = 1e6 * rng.normal(size=(3, n_gas_particles))\n",
    "ppmg = np.ones(n_gas_particles)\n",
    "hsml = 10000 * np.ones(n_gas_particles)\n",
    "dens = 2.0e-4 * np.ones(n_gas_particles)\n",
    "\n",
    "ppxd, ppyd, ppzd = 1e6 * rng.normal(size=(3, n_dm_particles))\n",
    "ppmd = np.ones(n_dm_particles)\n",
    "\n",
    "ppxs, ppys, ppzs = 5e5 * rng.normal(size=(3, n_star_particles))\n",
    "ppms = 0.1 * np.ones(n_star_particles)\n",
    "\n",
    "bbox = 1.1 * np.array(\n",
    "    [\n",
    "        [\n",
    "            min(ppxg.min(), ppxd.min(), ppxs.min()),\n",
    "            max(ppxg.max(), ppxd.max(), ppxs.max()),\n",
    "        ],\n",
    "        [\n",
    "            min(ppyg.min(), ppyd.min(), ppys.min()),\n",
    "            max(ppyg.max(), ppyd.max(), ppys.max()),\n",
    "        ],\n",
    "        [\n",
    "            min(ppzg.min(), ppzd.min(), ppzs.min()),\n",
    "            max(ppzg.max(), ppzd.max(), ppzs.max()),\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "data2 = {\n",
    "    (\"gas\", \"particle_position_x\"): ppxg,\n",
    "    (\"gas\", \"particle_position_y\"): ppyg,\n",
    "    (\"gas\", \"particle_position_z\"): ppzg,\n",
    "    (\"gas\", \"particle_mass\"): ppmg,\n",
    "    (\"gas\", \"smoothing_length\"): hsml,\n",
    "    (\"gas\", \"density\"): dens,\n",
    "    (\"dm\", \"particle_position_x\"): ppxd,\n",
    "    (\"dm\", \"particle_position_y\"): ppyd,\n",
    "    (\"dm\", \"particle_position_z\"): ppzd,\n",
    "    (\"dm\", \"particle_mass\"): ppmd,\n",
    "    (\"star\", \"particle_position_x\"): ppxs,\n",
    "    (\"star\", \"particle_position_y\"): ppys,\n",
    "    (\"star\", \"particle_position_z\"): ppzs,\n",
    "    (\"star\", \"particle_mass\"): ppms,\n",
    "}\n",
    "\n",
    "ds2 = yt.load_particles(\n",
    "    data2, length_unit=1.0 * parsec, mass_unit=1e8 * Msun, bbox=bbox\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have separate `\"gas\"`, `\"dm\"`, and `\"star\"` particles. Since the `\"gas\"` particles have `\"density\"` and `\"smoothing_length\"` fields, they are recognized as SPH particles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = ds2.all_data()\n",
    "c = np.array([ad.mean((\"gas\", ax)).to(\"code_length\") for ax in \"xyz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slc = yt.SlicePlot(ds2, \"z\", (\"gas\", \"density\"), center=c)\n",
    "slc.set_zlim((\"gas\", \"density\"), 1e-19, 2.0e-18)\n",
    "slc.set_width((4, \"Mpc\"))\n",
    "slc.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
